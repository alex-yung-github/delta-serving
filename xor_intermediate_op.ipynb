{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Matrix Bitwise XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bitwise_xor(a, b):\n",
    "    \"\"\"Scalar XOR: a ^ b = a + b - 2 * (a & b)\"\"\"\n",
    "    return a + b - 2 * (a & b)\n",
    "\n",
    "def matrix_xor(M_a, M_b):\n",
    "    \"\"\"\n",
    "    Computes element-wise a XOR b for numpy arrays a and b using the arithmetic rearrangement:\n",
    "    M_a ^ M_b = M_a + b - 2 * (M_a & M_b)\n",
    "    Assumes a and b are numpy arrays of non-negative integers with compatible shapes.\n",
    "    \"\"\"\n",
    "    return M_a + M_b - 2 * np.bitwise_and(M_a, M_b)\n",
    "\n",
    "def x_times_matrix_xor(x, M_a, M_b):\n",
    "    \"\"\"\n",
    "    Computes x @ (M_a XOR M_b) where XOR is element-wise, and @ is matrix multiplication.\n",
    "    Assumes x is a numpy array (matrix), and a, b are numpy arrays (matrices) of non-negative integers\n",
    "    with shapes such that matrix multiplication is valid (x.shape[1] == a.shape[0], and a.shape == b.shape).\n",
    "    \"\"\"\n",
    "    xor_ab = matrix_xor(M_a, M_b)\n",
    "    return np.matmul(x, xor_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=1, b=2: impl=3 == expected=3 == builtin=3\n",
      "a=3, b=1: impl=2 == expected=2 == builtin=2\n",
      "a=0, b=0: impl=0 == expected=0 == builtin=0\n",
      "a=7, b=7: impl=0 == expected=0 == builtin=0\n",
      "a=12345, b=67890: impl=80139 == expected=80139 == builtin=80139\n"
     ]
    }
   ],
   "source": [
    "tests_scalar = [\n",
    "    (1, 2, 3),\n",
    "    (3, 1, 2),\n",
    "    (0, 0, 0),\n",
    "    (7, 7, 0),\n",
    "    (12345, 67890, 80139)\n",
    "]\n",
    "for a, b, expected in tests_scalar:\n",
    "    impl = bitwise_xor(a, b)\n",
    "    builtin = np.bitwise_xor(a, b)\n",
    "    print(f\"a={a}, b={b}: impl={impl} == expected={expected} == builtin={builtin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2]\n",
      "[3 2]\n",
      "[0 0]\n",
      "[6 0]\n"
     ]
    }
   ],
   "source": [
    "a_vec = np.array([1, 3])\n",
    "b_vec = np.array([2, 1])\n",
    "print(matrix_xor(a_vec, b_vec))  # [3 2]\n",
    "print(np.bitwise_xor(a_vec, b_vec))  # [3 2]\n",
    "\n",
    "a_zero = np.array([0, 0])\n",
    "print(matrix_xor(a_zero, a_zero))  # [0 0]\n",
    "\n",
    "a_mixed = np.array([5, 7])\n",
    "b_mixed = np.array([3, 7])\n",
    "print(matrix_xor(a_mixed, b_mixed))  # [6 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer XOR Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def bitwise_xor(a, b):\n",
    "    \"\"\"Scalar XOR: a ^ b = a + b - 2 * (a & b)\"\"\"\n",
    "    return a + b - 2 * (a & b)\n",
    "\n",
    "def matrix_xor(M_a, M_b):\n",
    "    \"\"\"\n",
    "    Computes element-wise a XOR b for numpy arrays a and b using the arithmetic rearrangement.\n",
    "    Assumes a and b are numpy arrays of non-negative integers with compatible shapes.\n",
    "    \"\"\"\n",
    "    return M_a + M_b - 2 * np.bitwise_and(M_a, M_b)\n",
    "\n",
    "def x_times_matrix_xor(x, M_a, M_b):\n",
    "    \"\"\"\n",
    "    Computes x @ (M_a XOR M_b) where XOR is element-wise, and @ is matrix multiplication.\n",
    "    Assumes x is a numpy array (matrix), and a, b are numpy arrays with compatible shapes.\n",
    "    \"\"\"\n",
    "    xor_ab = matrix_xor(M_a, M_b)\n",
    "    return np.matmul(x, xor_ab)\n",
    "\n",
    "def apply_xor_to_weights_and_evaluate(transformer, input_data, target_data, scale_factor=1000):\n",
    "    \"\"\"\n",
    "    Applies bitwise XOR transformation to transformer weight matrices and evaluates performance.\n",
    "    Args:\n",
    "        transformer: TinyTransformerLayer instance\n",
    "        input_data: Input tensor (batch_size, seq_len, d_model)\n",
    "        target_data: Target tensor for comparison\n",
    "        scale_factor: Factor to convert float weights to integers for bitwise ops\n",
    "    Returns:\n",
    "        original_output: Output with original weights\n",
    "        modified_output: Output with XOR-modified weights\n",
    "        mse_loss: Mean squared error between original and modified outputs\n",
    "    \"\"\"\n",
    "    # Store original weights\n",
    "    original_weights = {}\n",
    "    for name, param in transformer.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            original_weights[name] = param.data.clone()\n",
    "\n",
    "    # Apply XOR transformation\n",
    "    for name, param in transformer.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Convert to integer range for bitwise ops\n",
    "            weight_np = param.data.cpu().numpy()\n",
    "            scaled_weight = np.round(weight_np * scale_factor).astype(int)\n",
    "            # Apply XOR with a reference matrix (e.g., itself or a constant)\n",
    "            xor_weight = matrix_xor(scaled_weight, scaled_weight)  # Self-XOR as example\n",
    "            # Scale back and clip to original range\n",
    "            param.data.copy_(torch.tensor((xor_weight / scale_factor).clip(min=weight_np.min(), max=weight_np.max()), device=param.device))\n",
    "\n",
    "    # Forward pass with modified weights\n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        modified_output = transformer(input_data)\n",
    "\n",
    "    # Restore original weights\n",
    "    for name, param in transformer.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            param.data.copy_(original_weights[name])\n",
    "\n",
    "    # Forward pass with original weights\n",
    "    original_output = transformer(input_data)\n",
    "\n",
    "    # Compute MSE loss\n",
    "    mse_loss = F.mse_loss(modified_output, original_output).item()\n",
    "\n",
    "    return original_output, modified_output, mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original output shape: torch.Size([2, 10, 64]), Modified output shape: torch.Size([2, 10, 64])\n",
      "MSE between original and modified outputs: 0.06542350351810455\n"
     ]
    }
   ],
   "source": [
    "# Define TinyTransformerLayer (as provided)\n",
    "class TinyTransformerLayer(nn.Module):\n",
    "    \"\"\"Small block with MHA + FFN, sufficient for demonstration.\"\"\"\n",
    "    def __init__(self, d_model=64, nhead=4, dim_feedforward=128, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True, dropout=dropout)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim_feedforward, d_model),\n",
    "        )\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        h = self.ln1(x)\n",
    "        a, _ = self.self_attn(h, h, h, attn_mask=attn_mask)\n",
    "        x = x + a\n",
    "        h2 = self.ln2(x)\n",
    "        y = self.ff(h2)\n",
    "        return x + y\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize transformer\n",
    "    transformer = TinyTransformerLayer(d_model=64, nhead=4, dim_feedforward=128)\n",
    "    transformer.eval()\n",
    "\n",
    "    # Dummy input and target data\n",
    "    batch_size, seq_len, d_model = 2, 10, 64\n",
    "    input_data = torch.randn(batch_size, seq_len, d_model)\n",
    "    target_data = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "    # Apply XOR and evaluate\n",
    "    orig_out, mod_out, mse = apply_xor_to_weights_and_evaluate(transformer, input_data, target_data, scale_factor=1000)\n",
    "    print(f\"Original output shape: {orig_out.shape}, Modified output shape: {mod_out.shape}\")\n",
    "    print(f\"MSE between original and modified outputs: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
